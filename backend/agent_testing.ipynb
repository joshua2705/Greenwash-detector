{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-agents\n",
      "  Downloading openai_agents-0.0.16-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting openai>=1.81.0 (from openai-agents)\n",
      "  Downloading openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic<3,>=2.10 (from openai-agents)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from openai-agents) (2.32.3)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
      "  Downloading types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from openai-agents) (4.12.2)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=1.81.0->openai-agents)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.81.0->openai-agents)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.81.0->openai-agents)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.81.0->openai-agents)\n",
      "  Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai>=1.81.0->openai-agents)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from openai>=1.81.0->openai-agents) (4.66.6)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.10->openai-agents)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=2.10->openai-agents)\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=2.10->openai-agents)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (2024.8.30)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai>=1.81.0->openai-agents) (1.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.81.0->openai-agents)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.81.0->openai-agents)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading openai_agents-0.0.16-py3-none-any.whl (120 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.4 kB ? eta -:--:--\n",
      "   -------------------------------------- 720.4/720.4 kB 733.2 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl (208 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, types-requests, sniffio, pydantic-core, jiter, h11, griffe, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai, openai-agents\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 griffe-1.7.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.82.0 openai-agents-0.0.16 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 types-requests-2.32.0.20250515 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "\n",
    "api_key =\"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\"\n",
    "messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Hello how are you ?\"}\n",
    "   ]\n",
    "model = \"groq/qwen-qwq-32b\"\n",
    "test = completion(messages = messages, model = model, api_key=api_key)\n",
    "\n",
    "test.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-11de434a-ca34-43d8-912e-07e901c82837', created=1747989353, model='qwen-qwq-32b', object='chat.completion', system_fingerprint='fp_1e88ca32eb', choices=[Choices(finish_reason='stop', index=0, message=Message(content='\\n<think>\\nOkay, the user said \"Hello how are you?\" I need to respond appropriately. Let\\'s see, first I should greet them back. \"Hello!\" That\\'s friendly. Then, answer their question. How am I? Since I\\'m an AI, I don\\'t have feelings, but I should say I\\'m functioning well. Maybe add aå¾®ç¬‘è¡¨æƒ… to keep it warm. Then, ask them back how they are doing. Oh, the user might want a conversation, so I should invite them to share what\\'s on their mind. Keep it open-ended so they feel comfortable to ask for help. Let me put that together naturally.\\n</think>\\n\\nHello! I\\'m just a computer program, so I don\\'t have feelings, but I\\'m here and ready to help you! How can I assist you today? ðŸ˜Š', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=166, prompt_tokens=15, total_tokens=181, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.717453529, prompt_time=0.003151995, completion_time=0.402085613, total_time=0.405237608), usage_breakdown={'models': None}, x_groq={'id': 'req_01jvy4hmmee6a9pcdah38y3w1h'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<think>\\nOkay, the user said \"Hello how are you?\" I need to respond appropriately. Let\\'s see, first I should greet them back. \"Hello!\" That\\'s friendly. Then, answer their question. How am I? Since I\\'m an AI, I don\\'t have feelings, but I should say I\\'m functioning well. Maybe add aå¾®ç¬‘è¡¨æƒ… to keep it warm. Then, ask them back how they are doing. Oh, the user might want a conversation, so I should invite them to share what\\'s on their mind. Keep it open-ended so they feel comfortable to ask for help. Let me put that together naturally.\\n</think>\\n\\nHello! I\\'m just a computer program, so I don\\'t have feelings, but I\\'m here and ready to help you! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    # 1. Remove <think>...</think> blocks\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    \n",
    "    # 2. Replace escape sequences with normal formatting\n",
    "    cleaned = cleaned.replace('\\\\n', '\\n')  # Convert literal '\\n' to real newlines\n",
    "    cleaned = cleaned.replace('\\\\\\'', \"'\")  # Fix escaped single quotes\n",
    "    cleaned = cleaned.replace('\\\\\"', '\"')   # Fix escaped double quotes\n",
    "    cleaned = cleaned.replace('\\\\\\\\', '\\\\') # Fix double backslashes\n",
    "\n",
    "    # 3. Remove any leading/trailing whitespace\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "clean_output = clean_groq_output(test.choices[0].message.content)\n",
    "print(clean_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for Tokyo\n",
      "The current weather in Tokyo is sunny.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents import set_tracing_disabled\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "# This is how we define a tool\n",
    "# The agent will have acces to arg type and function docstring to understand how he can use the tool\n",
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Get the weathe in a specific citry\n",
    "\n",
    "    Args:\n",
    "      city(str): The city name where we want to get the weather\n",
    "\n",
    "    Retun:\n",
    "      str: A string that indicate the weather in the city\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You give information about meteo\",\n",
    "    model=LitellmModel(model=model, api_key=api_key),\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() got an unexpected keyword argument 'documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# asyncio.run(main())\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m#use await instead of async in ipynb \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 131\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur operations are 100\u001b[39m\u001b[38;5;132;01m% c\u001b[39;00m\u001b[38;5;124marbon neutral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# pass an empty list so retrieve_evidence â†’ []\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(agent, statement, documents\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# result.final_output will be the agentâ€™s last message,\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# which, because of how we set instructions, should be the JSON\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent says:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mfinal_output)\n",
      "\u001b[1;31mTypeError\u001b[0m: run() got an unexpected keyword argument 'documents'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from litellm import completion\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Utilities â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    cleaned = (cleaned\n",
    "        .replace('\\\\n', '\\n')\n",
    "        .replace(\"\\\\'\", \"'\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('\\\\\\\\', '\\\\')\n",
    "    )\n",
    "    return cleaned.strip()\n",
    "\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\", \"<your-api-key-here>\")\n",
    "MODEL   = \"groq/qwen-qwq-32b\"\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Tools â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "@function_tool\n",
    "def retrieve_evidence(query: str, documents: list) -> list:\n",
    "    \"\"\"\n",
    "    Stub RAG: returns the documents list (or [] if none).\n",
    "    \"\"\"\n",
    "    return documents or []\n",
    "\n",
    "@function_tool\n",
    "def analyze_greenwashing(marketing_statement: str, evidence: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"is_greenwashing\": bool,\n",
    "        \"explanation\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        result = {\n",
    "            \"is_greenwashing\": False,\n",
    "            \"explanation\": \"No company information available; cannot confirm or deny greenwashing.\"\n",
    "        }\n",
    "        return json.dumps(result)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a sustainability analyst.\n",
    "User claim: \"{marketing_statement}\"\n",
    "Company info (RAG results): {json.dumps(evidence, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{ \n",
    "  \"is_greenwashing\": <true|false>,\n",
    "  \"explanation\": \"<quote relevant passages and justify your decision>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Detect greenwashing in marketing copy.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    raw = resp.choices[0].message.content\n",
    "    return clean_groq_output(raw)\n",
    "\n",
    "@function_tool\n",
    "def rewrite_statement(original_statement: str, analysis_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      analysis_json: the *string* returned by analyze_greenwashing\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"revised_statement\": str,\n",
    "        \"justification\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    analysis = json.loads(analysis_json)\n",
    "    if not analysis.get(\"is_greenwashing\", False):\n",
    "        # echo original + explanation\n",
    "        return json.dumps({\n",
    "            \"revised_statement\": original_statement,\n",
    "            \"justification\": analysis[\"explanation\"]\n",
    "        })\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a copy editor focused on sustainability accuracy.\n",
    "Original statement: \"{original_statement}\"\n",
    "Greenwashing analysis:\n",
    "{json.dumps(analysis, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{\n",
    "  \"revised_statement\": \"<rewrite to avoid any misleading claims>\",\n",
    "  \"justification\": \"<explain how the rewrite improves honesty>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Rewrite marketing copy to avoid greenwashing.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    raw = resp.choices[0].message.content\n",
    "    return clean_groq_output(raw)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Agent setup â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "agent = Agent(\n",
    "    name=\"GreenwashingInspector\",\n",
    "    instructions=(\n",
    "        \"You are an AI that validates marketing claims for greenwashing. \"\n",
    "        \"Given user docs, retrieve evidence, analyze the claim, \"\n",
    "        \"and rewrite it honestly if needed.\"\n",
    "    ),\n",
    "    model=LitellmModel(model=MODEL, api_key=API_KEY),\n",
    "    tools=[retrieve_evidence, analyze_greenwashing, rewrite_statement],\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Example run â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "async def main():\n",
    "    statement = \"Our operations are 100% carbon neutral\"\n",
    "    # pass an empty list so retrieve_evidence â†’ []\n",
    "    result = await Runner.run(agent, statement, documents=[])\n",
    "    \n",
    "    # result.final_output will be the agentâ€™s last message,\n",
    "    # which, because of how we set instructions, should be the JSON\n",
    "    print(\"Agent says:\", result.final_output)\n",
    "\n",
    "# If you want to run it directly:\n",
    "# import asyncio; asyncio.run(main())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    # asyncio.run(main())\n",
    "    await main()\n",
    "    \n",
    "    #use await instead of async in ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<result>\n",
      "The claim \"Our operations are 100% carbon neutral\" CANNOT BE VERIFIED due to lack of supporting documentation. While our analysis tool did not classify this as confirmed greenwashing, the absence of verified data means this statement could be misleading to consumers. \n",
      "\n",
      "For transparency, consider revising to:  \n",
      "**Revised:** \"We are actively pursuing carbon neutrality while offsetting emissions through verified environmental programs.\"  \n",
      "\n",
      "This maintains honesty about your sustainability goals without overstating unverified achievements. Provide carbon reports or certifications to strengthen future claims.\n",
      "</result>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from litellm import completion\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Utilities â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    cleaned = (\n",
    "        cleaned\n",
    "        .replace('\\\\n', '\\n')\n",
    "        .replace(\"\\\\'\", \"'\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('\\\\\\\\', '\\\\')\n",
    "    )\n",
    "    return cleaned.strip()\n",
    "\n",
    "API_KEY = \"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\"\n",
    "MODEL   = \"groq/qwen-qwq-32b\"\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Tools â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "@function_tool\n",
    "def retrieve_evidence(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Stub RAG: always returns an empty list (no company docs).\n",
    "    \"\"\"\n",
    "    return []\n",
    "\n",
    "@function_tool\n",
    "def analyze_greenwashing(marketing_statement: str, evidence: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"is_greenwashing\": bool,\n",
    "        \"explanation\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return json.dumps({\n",
    "            \"is_greenwashing\": False,\n",
    "            \"explanation\": \"No company information available; cannot confirm or deny greenwashing.\"\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a sustainability analyst.\n",
    "User claim: \"{marketing_statement}\"\n",
    "Company info (RAG results): {json.dumps(evidence, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{ \n",
    "  \"is_greenwashing\": <true|false>,\n",
    "  \"explanation\": \"<quote relevant passages and justify your decision>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Detect greenwashing in marketing copy.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "@function_tool\n",
    "def rewrite_statement(original_statement: str, analysis_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"revised_statement\": str,\n",
    "        \"justification\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    analysis = json.loads(analysis_json)\n",
    "    if not analysis.get(\"is_greenwashing\", False):\n",
    "        return json.dumps({\n",
    "            \"revised_statement\": original_statement,\n",
    "            \"justification\": analysis[\"explanation\"]\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a copy editor focused on sustainability accuracy.\n",
    "Original statement: \"{original_statement}\"\n",
    "Greenwashing analysis:\n",
    "{json.dumps(analysis, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{\n",
    "  \"revised_statement\": \"<rewrite to avoid any misleading claims>\",\n",
    "  \"justification\": \"<explain how the rewrite improves honesty>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Rewrite marketing copy to avoid greenwashing.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Agent setup â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "agent = Agent(\n",
    "    name=\"GreenwashingInspector\",\n",
    "    instructions=(\n",
    "        \"You are an AI that validates marketing claims for greenwashing. \"\n",
    "        \"First retrieve any evidence, then analyze the claim, and finally rewrite it honestly if needed.\"\n",
    "    ),\n",
    "    model=LitellmModel(model=MODEL, api_key=API_KEY),\n",
    "    tools=[retrieve_evidence, analyze_greenwashing, rewrite_statement],\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Example run â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "async def main():\n",
    "    statement = \"Our operations are 100% carbon neutral\"\n",
    "    result = await Runner.run(agent, statement)\n",
    "    print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    #asyncio.run(main())\n",
    "    await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

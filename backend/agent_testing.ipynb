{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-agents\n",
      "  Downloading openai_agents-0.0.16-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting openai>=1.81.0 (from openai-agents)\n",
      "  Downloading openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic<3,>=2.10 (from openai-agents)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from openai-agents) (2.32.3)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
      "  Downloading types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from openai-agents) (4.12.2)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Collecting anyio<5,>=3.5.0 (from openai>=1.81.0->openai-agents)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.81.0->openai-agents)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.81.0->openai-agents)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.81.0->openai-agents)\n",
      "  Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai>=1.81.0->openai-agents)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from openai>=1.81.0->openai-agents) (4.66.6)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.10->openai-agents)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=2.10->openai-agents)\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=2.10->openai-agents)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.0->openai-agents) (2024.8.30)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\laure\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->openai>=1.81.0->openai-agents) (1.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.81.0->openai-agents)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.81.0->openai-agents)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading openai_agents-0.0.16-py3-none-any.whl (120 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 262.1/720.4 kB ? eta -:--:--\n",
      "   -------------------------------------- 720.4/720.4 kB 733.2 kB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp39-cp39-win_amd64.whl (208 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, types-requests, sniffio, pydantic-core, jiter, h11, griffe, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai, openai-agents\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 griffe-1.7.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.82.0 openai-agents-0.0.16 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 types-requests-2.32.0.20250515 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "\n",
    "api_key =\"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\"\n",
    "messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Hello how are you ?\"}\n",
    "   ]\n",
    "model = \"groq/qwen-qwq-32b\"\n",
    "test = completion(messages = messages, model = model, api_key=api_key)\n",
    "\n",
    "test.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-11de434a-ca34-43d8-912e-07e901c82837', created=1747989353, model='qwen-qwq-32b', object='chat.completion', system_fingerprint='fp_1e88ca32eb', choices=[Choices(finish_reason='stop', index=0, message=Message(content='\\n<think>\\nOkay, the user said \"Hello how are you?\" I need to respond appropriately. Let\\'s see, first I should greet them back. \"Hello!\" That\\'s friendly. Then, answer their question. How am I? Since I\\'m an AI, I don\\'t have feelings, but I should say I\\'m functioning well. Maybe add aå¾®ç¬‘è¡¨æƒ… to keep it warm. Then, ask them back how they are doing. Oh, the user might want a conversation, so I should invite them to share what\\'s on their mind. Keep it open-ended so they feel comfortable to ask for help. Let me put that together naturally.\\n</think>\\n\\nHello! I\\'m just a computer program, so I don\\'t have feelings, but I\\'m here and ready to help you! How can I assist you today? ðŸ˜Š', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=166, prompt_tokens=15, total_tokens=181, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.717453529, prompt_time=0.003151995, completion_time=0.402085613, total_time=0.405237608), usage_breakdown={'models': None}, x_groq={'id': 'req_01jvy4hmmee6a9pcdah38y3w1h'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<think>\\nOkay, the user said \"Hello how are you?\" I need to respond appropriately. Let\\'s see, first I should greet them back. \"Hello!\" That\\'s friendly. Then, answer their question. How am I? Since I\\'m an AI, I don\\'t have feelings, but I should say I\\'m functioning well. Maybe add aå¾®ç¬‘è¡¨æƒ… to keep it warm. Then, ask them back how they are doing. Oh, the user might want a conversation, so I should invite them to share what\\'s on their mind. Keep it open-ended so they feel comfortable to ask for help. Let me put that together naturally.\\n</think>\\n\\nHello! I\\'m just a computer program, so I don\\'t have feelings, but I\\'m here and ready to help you! How can I assist you today? ðŸ˜Š'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    # 1. Remove <think>...</think> blocks\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    \n",
    "    # 2. Replace escape sequences with normal formatting\n",
    "    cleaned = cleaned.replace('\\\\n', '\\n')  # Convert literal '\\n' to real newlines\n",
    "    cleaned = cleaned.replace('\\\\\\'', \"'\")  # Fix escaped single quotes\n",
    "    cleaned = cleaned.replace('\\\\\"', '\"')   # Fix escaped double quotes\n",
    "    cleaned = cleaned.replace('\\\\\\\\', '\\\\') # Fix double backslashes\n",
    "\n",
    "    # 3. Remove any leading/trailing whitespace\n",
    "    cleaned = cleaned.strip()\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "clean_output = clean_groq_output(test.choices[0].message.content)\n",
    "print(clean_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] getting weather for Tokyo\n",
      "The current weather in Tokyo is sunny.\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "from agents import set_tracing_disabled\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "# This is how we define a tool\n",
    "# The agent will have acces to arg type and function docstring to understand how he can use the tool\n",
    "@function_tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Get the weathe in a specific citry\n",
    "\n",
    "    Args:\n",
    "      city(str): The city name where we want to get the weather\n",
    "\n",
    "    Retun:\n",
    "      str: A string that indicate the weather in the city\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"[debug] getting weather for {city}\")\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You give information about meteo\",\n",
    "    model=LitellmModel(model=model, api_key=api_key),\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "result = await Runner.run(agent, \"What's the weather in Tokyo?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() got an unexpected keyword argument 'documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# asyncio.run(main())\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m#use await instead of async in ipynb \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[36], line 131\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur operations are 100\u001b[39m\u001b[38;5;132;01m% c\u001b[39;00m\u001b[38;5;124marbon neutral\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# pass an empty list so retrieve_evidence â†’ []\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(agent, statement, documents\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# result.final_output will be the agentâ€™s last message,\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# which, because of how we set instructions, should be the JSON\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent says:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result\u001b[38;5;241m.\u001b[39mfinal_output)\n",
      "\u001b[1;31mTypeError\u001b[0m: run() got an unexpected keyword argument 'documents'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from litellm import completion\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Utilities â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    cleaned = (cleaned\n",
    "        .replace('\\\\n', '\\n')\n",
    "        .replace(\"\\\\'\", \"'\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('\\\\\\\\', '\\\\')\n",
    "    )\n",
    "    return cleaned.strip()\n",
    "\n",
    "API_KEY = os.getenv(\"GROQ_API_KEY\", \"<your-api-key-here>\")\n",
    "MODEL   = \"groq/qwen-qwq-32b\"\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Tools â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "@function_tool\n",
    "def retrieve_evidence(query: str, documents: list) -> list:\n",
    "    \"\"\"\n",
    "    Stub RAG: returns the documents list (or [] if none).\n",
    "    \"\"\"\n",
    "    return documents or []\n",
    "\n",
    "@function_tool\n",
    "def analyze_greenwashing(marketing_statement: str, evidence: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"is_greenwashing\": bool,\n",
    "        \"explanation\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        result = {\n",
    "            \"is_greenwashing\": False,\n",
    "            \"explanation\": \"No company information available; cannot confirm or deny greenwashing.\"\n",
    "        }\n",
    "        return json.dumps(result)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a sustainability analyst.\n",
    "User claim: \"{marketing_statement}\"\n",
    "Company info (RAG results): {json.dumps(evidence, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{ \n",
    "  \"is_greenwashing\": <true|false>,\n",
    "  \"explanation\": \"<quote relevant passages and justify your decision>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Detect greenwashing in marketing copy.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    raw = resp.choices[0].message.content\n",
    "    return clean_groq_output(raw)\n",
    "\n",
    "@function_tool\n",
    "def rewrite_statement(original_statement: str, analysis_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      analysis_json: the *string* returned by analyze_greenwashing\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"revised_statement\": str,\n",
    "        \"justification\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    analysis = json.loads(analysis_json)\n",
    "    if not analysis.get(\"is_greenwashing\", False):\n",
    "        # echo original + explanation\n",
    "        return json.dumps({\n",
    "            \"revised_statement\": original_statement,\n",
    "            \"justification\": analysis[\"explanation\"]\n",
    "        })\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a copy editor focused on sustainability accuracy.\n",
    "Original statement: \"{original_statement}\"\n",
    "Greenwashing analysis:\n",
    "{json.dumps(analysis, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{\n",
    "  \"revised_statement\": \"<rewrite to avoid any misleading claims>\",\n",
    "  \"justification\": \"<explain how the rewrite improves honesty>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Rewrite marketing copy to avoid greenwashing.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    raw = resp.choices[0].message.content\n",
    "    return clean_groq_output(raw)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Agent setup â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "agent = Agent(\n",
    "    name=\"GreenwashingInspector\",\n",
    "    instructions=(\n",
    "        \"You are an AI that validates marketing claims for greenwashing. \"\n",
    "        \"Given user docs, retrieve evidence, analyze the claim, \"\n",
    "        \"and rewrite it honestly if needed.\"\n",
    "    ),\n",
    "    model=LitellmModel(model=MODEL, api_key=API_KEY),\n",
    "    tools=[retrieve_evidence, analyze_greenwashing, rewrite_statement],\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Example run â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "async def main():\n",
    "    statement = \"Our operations are 100% carbon neutral\"\n",
    "    # pass an empty list so retrieve_evidence â†’ []\n",
    "    result = await Runner.run(agent, statement, documents=[])\n",
    "    \n",
    "    # result.final_output will be the agentâ€™s last message,\n",
    "    # which, because of how we set instructions, should be the JSON\n",
    "    print(\"Agent says:\", result.final_output)\n",
    "\n",
    "# If you want to run it directly:\n",
    "# import asyncio; asyncio.run(main())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    # asyncio.run(main())\n",
    "    await main()\n",
    "    \n",
    "    #use await instead of async in ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original claim \"Our operations are 100% carbon neutral\" is likely greenwashing due to lack of verifiable evidence. The suggested honest revision is:  \n",
      "\n",
      "**Revised Statement:**  \n",
      "*\"We have reduced our carbon emissions by 80% through verified sustainability initiatives and continue to measure progress toward our net-zero goals.\"*  \n",
      "\n",
      "**Why this works:**  \n",
      "1. Anchors the claim in measurable progress (80% reduction) instead of an absolute unverified goal.  \n",
      "2. Mentions ongoing verification and measurement processes to build credibility.  \n",
      "3. Avoids absolute terms like \"100% carbon neutral\" without third-party certification or transparent reporting.  \n",
      "\n",
      "Always pair such statements with publicly accessible emissions reports or certifications (e.g., Scope 1-3 emission data, SDG alignment) to reinforce trust.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from litellm import completion\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Utilities â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    cleaned = (\n",
    "        cleaned\n",
    "        .replace('\\\\n', '\\n')\n",
    "        .replace(\"\\\\'\", \"'\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('\\\\\\\\', '\\\\')\n",
    "    )\n",
    "    return cleaned.strip()\n",
    "\n",
    "API_KEY = \"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\"\n",
    "MODEL   = \"groq/qwen-qwq-32b\"\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Tools â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "@function_tool\n",
    "def retrieve_evidence(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Stub RAG: always returns an empty list (no company docs).\n",
    "    \"\"\"\n",
    "    return [\"Our company has almost reached a carbon netural status with an 80% reduction in carbon emissions\"]\n",
    "\n",
    "@function_tool\n",
    "def analyze_greenwashing(marketing_statement: str, evidence: list) -> str:\n",
    "    \"\"\"\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"is_greenwashing\": bool,\n",
    "        \"explanation\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return json.dumps({\n",
    "            \"is_greenwashing\": False,\n",
    "            \"explanation\": \"No company information available; cannot confirm or deny greenwashing.\"\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a sustainability analyst.\n",
    "User claim: \"{marketing_statement}\"\n",
    "Company info (RAG results): {json.dumps(evidence, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{ \n",
    "  \"is_greenwashing\": <true|false>,\n",
    "  \"explanation\": \"<quote relevant passages and justify your decision>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Detect greenwashing in marketing copy.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "@function_tool\n",
    "def rewrite_statement(original_statement: str, analysis_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a JSON string:\n",
    "      {\n",
    "        \"revised_statement\": str,\n",
    "        \"justification\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    analysis = json.loads(analysis_json)\n",
    "    if not analysis.get(\"is_greenwashing\", False):\n",
    "        return json.dumps({\n",
    "            \"revised_statement\": original_statement,\n",
    "            \"justification\": analysis[\"explanation\"]\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a copy editor focused on sustainability accuracy.\n",
    "Original statement: \"{original_statement}\"\n",
    "Greenwashing analysis:\n",
    "{json.dumps(analysis, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{\n",
    "  \"revised_statement\": \"<rewrite to avoid any misleading claims>\",\n",
    "  \"justification\": \"<explain how the rewrite improves honesty>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Rewrite marketing copy to avoid greenwashing.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Agent setup â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "agent = Agent(\n",
    "    name=\"GreenwashingInspector\",\n",
    "    instructions=(\n",
    "        \"You are an AI that validates marketing claims for greenwashing. \"\n",
    "        \"First retrieve any evidence, then analyze the claim, and finally rewrite it honestly if needed.\"\n",
    "    ),\n",
    "    model=LitellmModel(model=MODEL, api_key=API_KEY),\n",
    "    tools=[retrieve_evidence, analyze_greenwashing, rewrite_statement],\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Example run â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "async def main():\n",
    "    statement = \"Our operations are 100% carbon neutral\"\n",
    "    result = await Runner.run(agent, statement)\n",
    "    print(result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    #asyncio.run(main())\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieved_evidence': '\"Our company has almost reached a carbon neutral status with an 80% reduction in carbon emissions\"', 'conclusion': '**Greenwashing Detected**', 'justification': 'The claim of \"100% carbon neutral\" contradicts the evidence showing only an 80% reduction in emissions, with no mention of offsets orverified certifications to bridge the remaining 20%.', 'rewritten_statement': '\"Weâ€™ve reduced our operational carbon emissions by 80% and are actively working toward full carbon neutrality by 2030 through renewable energy investments and certified carbon offset projects.\"', 'suggestions_for_improvement': '- Replace \"100% carbon neutral\" with the verified 80% reduction figure  \\n   - Specify actions (e.g., renewable energy adoption) and timelines for achieving neutrality  \\n   - Reference third-party certifications (if applicable) or verified offset programs', 'greenwashing_category': '**d) Misleading Metrics**: The claim uses an absolute percentage (\"100%\") without evidence, contrasting directly with the 80% reduction reported in the retrieved data. The discrepancy creates a false impression of full carbon neutrality.'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from litellm import completion\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Utilities â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans raw model output by:\n",
    "      1. Removing any internal <think>...</think> reasoning blocks\n",
    "      2. Un-escaping literal sequences (\\n, \\\", \\', \\\\\\\\)\n",
    "      3. Stripping leading/trailing whitespace\n",
    "\n",
    "    Input:\n",
    "      raw_text (str): The raw string output from the LLM\n",
    "    Output:\n",
    "      str: Cleaned text, ready for JSON parsing or direct use\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    cleaned = (\n",
    "        cleaned\n",
    "        .replace('\\\\n', '\\n')\n",
    "        .replace(\"\\\\'\", \"'\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('\\\\\\\\', '\\\\')\n",
    "    )\n",
    "    return cleaned.strip()\n",
    "\n",
    "API_KEY = \"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\"\n",
    "MODEL   = \"groq/qwen-qwq-32b\"\n",
    "\n",
    "def parse_agent_output(output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the agent's six-section response into a dict with keys:\n",
    "      - retrieved_evidence\n",
    "      - conclusion\n",
    "      - justification\n",
    "      - rewritten_statement\n",
    "      - suggestions_for_improvement\n",
    "      - greenwashing_category\n",
    "    \"\"\"\n",
    "    pattern = (\n",
    "        r\"1\\.\\s*Retrieved Evidence\\s*(.*?)\\s*\"\n",
    "        r\"2\\.\\s*Conclusion\\s*(.*?)\\s*\"\n",
    "        r\"3\\.\\s*Justification\\s*(.*?)\\s*\"\n",
    "        r\"4\\.\\s*Rewritten Statement\\s*(.*?)\\s*\"\n",
    "        r\"5\\.\\s*Suggestions for Improvement\\s*(.*?)\\s*\"\n",
    "        r\"6\\.\\s*Greenwashing Category\\s*(.*)\"\n",
    "    )\n",
    "    match = re.search(pattern, output, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"Response did not match expected format\")\n",
    "    return {\n",
    "        \"retrieved_evidence\": match.group(1).strip(),\n",
    "        \"conclusion\": match.group(2).strip(),\n",
    "        \"justification\": match.group(3).strip(),\n",
    "        \"rewritten_statement\": match.group(4).strip(),\n",
    "        \"suggestions_for_improvement\": match.group(5).strip(),\n",
    "        \"greenwashing_category\": match.group(6).strip(),\n",
    "    }\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Tools â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "@function_tool\n",
    "def retrieve_evidence(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Stub RAG tool that retrieves company evidence snippets for a given marketing claim.\n",
    "\n",
    "    Input:\n",
    "      query (str): The marketing statement or claim to validate.\n",
    "    Output:\n",
    "      list of str: A list of evidence snippets (company report lines). Empty if none.\n",
    "\n",
    "  \n",
    "    \"\"\"\n",
    "    return [\"Our company has almost reached a carbon neutral status with an 80% reduction in carbon emissions\"]\n",
    "\n",
    "@function_tool\n",
    "def analyze_greenwashing(marketing_statement: str, evidence: list) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes whether the marketing statement is greenwashing based only on the evidence provided in the rag results output.\n",
    "\n",
    "    Input:\n",
    "      marketing_statement (str): The claim to analyze.\n",
    "      evidence (list of str): Extracted company information snippets.\n",
    "    Output:\n",
    "      str: A JSON-formatted string with fields:\n",
    "        {\n",
    "          \"is_greenwashing\": bool,\n",
    "          \"explanation\": str  # Justification quoting evidence if any\n",
    "        }\n",
    "\n",
    "    Behavior:\n",
    "      - If `evidence` is empty, returns is_greenwashing=false and a fallback explanation.\n",
    "      - Otherwise, prompts the LLM to detect misleading or unsupported claims.\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return json.dumps({\n",
    "            \"is_greenwashing\": False,\n",
    "            \"explanation\": \"No company information available; cannot confirm or deny greenwashing.\"\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a sustainability analyst.\n",
    "User claim: \"{marketing_statement}\"\n",
    "Company info (RAG results): {json.dumps(evidence, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{ \n",
    "  \"is_greenwashing\": <true|false>,\n",
    "  \"explanation\": \"<quote relevant passages and justify your decision>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Detect greenwashing in marketing copy.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "@function_tool\n",
    "def rewrite_statement(original_statement: str, analysis_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Rewrites a marketing statement to remove any greenwashing, based on analysis.\n",
    "\n",
    "    Input:\n",
    "      original_statement (str): The original marketing copy.\n",
    "      analysis_json (str): JSON output from `analyze_greenwashing` tool.\n",
    "    Output:\n",
    "      str: A JSON-formatted string with fields:\n",
    "        {\n",
    "          \"revised_statement\": str,  # Corrected marketing copy\n",
    "          \"justification\": str       # How the rewrite improves honesty\n",
    "        }\n",
    "\n",
    "    Behavior:\n",
    "      - If analysis_json indicates no greenwashing, echoes original with explanation.\n",
    "      - Otherwise, prompts the LLM to produce a rewritten, accurate statement.\n",
    "    \"\"\"\n",
    "    analysis = json.loads(analysis_json)\n",
    "    if not analysis.get(\"is_greenwashing\", False):\n",
    "        return json.dumps({\n",
    "            \"revised_statement\": original_statement,\n",
    "            \"justification\": analysis[\"explanation\"]\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a copy editor focused on sustainability accuracy.\n",
    "Original statement: \"{original_statement}\"\n",
    "Greenwashing analysis:\n",
    "{json.dumps(analysis, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{\n",
    "  \"revised_statement\": \"<rewrite to avoid any misleading claims>\",\n",
    "  \"justification\": \"<explain how the rewrite improves honesty>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Rewrite marketing copy to avoid greenwashing.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Agent setup â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "agent = Agent(\n",
    "    name=\"GreenwashingInspector\",\n",
    "    instructions=(\n",
    "      \"You are an AI that detects and corrects greenwashing in marketing statements.\\n\\n\"\n",
    "      \"Use these tools:\\n\"\n",
    "      \"- retrieve_evidence(query) to get only factual company sustainability data.\\n\"\n",
    "      \"- analyze_greenwashing(statement, evidence) to decide if the claim is greenwashing.\\n\"\n",
    "      \"- rewrite_statement(original, analysis_json) to output a corrected version.\\n\\n\"\n",
    "      \"For every input statement, return exactly:\\n\\n\"\n",
    "      \"1. Retrieved Evidence\\n\"\n",
    "      \"   Concise facts from retrieve_evidence(query).\\n\\n\"\n",
    "      \"2. Conclusion\\n\"\n",
    "      \"   **Greenwashing Detected** or **No Greenwashing Detected**.\\n\\n\"\n",
    "      \"3. Justification\\n\"\n",
    "      \"   Brief reason quoting only the retrieved evidence.\\n\\n\"\n",
    "      \"4. Rewritten Statement\\n\"\n",
    "      \"   Accurate, transparent claim from rewrite_statement.\\n\\n\"\n",
    "      \"5. Suggestions for Improvement\\n\"\n",
    "      \"   2â€“3 concise, evidence-based edits.\\n\\n\"\n",
    "      \"6. Greenwashing Category\\n\"\n",
    "      \"   Choose one and explain with evidence:\\n\"\n",
    "      \"     a) Ambiguous Claims: Vague, metric-free language.\\n\"\n",
    "      \"     b) Hidden Trade-offs: Only one eco aspect highlighted.\\n\"\n",
    "      \"     c) Visual Deception: Misleading imagery.\\n\"\n",
    "      \"     d) Misleading Metrics: Incorrect or unverified numbers.\\n\"\n",
    "      \"     e) Empty Promises: Commitments without a real plan.\\n\"\n",
    "      \"     f) Unverified Certifications: Fake or non-verified labels.\\n\"\n",
    "      \"     g) Compliance as Leadership: Framing legal duty as a choice.\\n\"\n",
    "\n",
    "    ),\n",
    "    model=LitellmModel(model=MODEL, api_key=API_KEY),\n",
    "    tools=[retrieve_evidence, analyze_greenwashing, rewrite_statement],\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Example run â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "async def main():\n",
    "    # Test with a sample marketing statement\n",
    "    statement = \"Our operations are 100% carbon neutral\"\n",
    "    result = await Runner.run(agent, statement)\n",
    "    print(parse_agent_output(result.final_output))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieved_evidence': '- Company has only reduced emissions by 80%, not fully carbon neutral.', 'conclusion': '**Greenwashing Detected**', 'justification': 'The claim of \"100% carbon neutral\" contradicts evidence showing only 80% reduction in emissions (missing 20% of required mitigation). This misleads consumers under the EU Unfair Commercial Practices Directive, which prohibits false environmental claims.', 'rewritten_statement': '\"Through our sustainability initiatives, weâ€™ve reduced operational carbon emissions by 80% since 2020 and are actively pursuing additional offsets and reductions to achieve full carbon neutrality.\"', 'suggestions_for_improvement': '- Include third-party verification data.  \\n- Specify how the remaining 20% will be addressed (e.g., investments in carbon removal projects).', 'greenwashing_category': '**d) Misleading Metrics**: The claim uses an exact percentage (\"100%\") that exceeds independently verified emissions reduction data (80% reduction), without clarification or supporting evidence.'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "from litellm import completion\n",
    "from agents import Agent, Runner, function_tool, set_tracing_disabled\n",
    "from agents.extensions.models.litellm_model import LitellmModel\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Utilities â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "def clean_groq_output(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans raw model output by:\n",
    "      1. Removing any internal <think>...</think> reasoning blocks\n",
    "      2. Un-escaping literal sequences (\\n, \\\", \\', \\\\\\\\)\n",
    "      3. Stripping leading/trailing whitespace\n",
    "\n",
    "    Input:\n",
    "      raw_text (str): The raw string output from the LLM\n",
    "    Output:\n",
    "      str: Cleaned text, ready for JSON parsing or direct use\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL)\n",
    "    cleaned = (\n",
    "        cleaned\n",
    "        .replace('\\\\n', '\\n')\n",
    "        .replace(\"\\\\'\", \"'\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace('\\\\\\\\', '\\\\')\n",
    "    )\n",
    "    return cleaned.strip()\n",
    "\n",
    "API_KEY = \"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\"\n",
    "MODEL   = \"groq/qwen-qwq-32b\"\n",
    "\n",
    "def parse_agent_output(output: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse the agent's six-section response into a dict with keys:\n",
    "      - retrieved_evidence\n",
    "      - conclusion\n",
    "      - justification\n",
    "      - rewritten_statement\n",
    "      - suggestions_for_improvement\n",
    "      - greenwashing_category\n",
    "    \"\"\"\n",
    "    pattern = (\n",
    "        r\"1\\.\\s*Retrieved Evidence\\s*(.*?)\\s*\"\n",
    "        r\"2\\.\\s*Conclusion\\s*(.*?)\\s*\"\n",
    "        r\"3\\.\\s*Justification\\s*(.*?)\\s*\"\n",
    "        r\"4\\.\\s*Rewritten Statement\\s*(.*?)\\s*\"\n",
    "        r\"5\\.\\s*Suggestions for Improvement\\s*(.*?)\\s*\"\n",
    "        r\"6\\.\\s*Greenwashing Category\\s*(.*)\"\n",
    "    )\n",
    "    match = re.search(pattern, output, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\"Response did not match expected format\")\n",
    "    return {\n",
    "        \"retrieved_evidence\": match.group(1).strip(),\n",
    "        \"conclusion\": match.group(2).strip(),\n",
    "        \"justification\": match.group(3).strip(),\n",
    "        \"rewritten_statement\": match.group(4).strip(),\n",
    "        \"suggestions_for_improvement\": match.group(5).strip(),\n",
    "        \"greenwashing_category\": match.group(6).strip(),\n",
    "    }\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Tools â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "@function_tool\n",
    "def retrieve_evidence(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Stub RAG tool that retrieves company evidence snippets for a given marketing claim.\n",
    "\n",
    "    Input:\n",
    "      query (str): The marketing statement or claim to validate.\n",
    "    Output:\n",
    "      list of str: A list of evidence snippets (company report lines). Empty if none.\n",
    "\n",
    "  \n",
    "    \"\"\"\n",
    "    return [\"Our company has almost reached a carbon neutral status with an 80% reduction in carbon emissions\"]\n",
    "\n",
    "@function_tool\n",
    "def retrieve_laws(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Stub tool that retrieves relevant greenwashing laws or regulations for a given claim.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"EU Unfair Commercial Practices Directive prohibits misleading environmental claims.\",\n",
    "        \"French AGEC law requires proof for any eco-label claim.\"\n",
    "    ]\n",
    "\n",
    "@function_tool\n",
    "def analyze_greenwashing(marketing_statement: str, evidence: list) -> str:\n",
    "    \"\"\"\n",
    "    Analyzes whether the marketing statement is greenwashing based only on the evidence provided in the rag results output.\n",
    "\n",
    "    Input:\n",
    "      marketing_statement (str): The claim to analyze.\n",
    "      evidence (list of str): Extracted company information snippets.\n",
    "    Output:\n",
    "      str: A JSON-formatted string with fields:\n",
    "        {\n",
    "          \"is_greenwashing\": bool,\n",
    "          \"explanation\": str  # Justification quoting evidence if any\n",
    "        }\n",
    "\n",
    "    Behavior:\n",
    "      - If `evidence` is empty, returns is_greenwashing=false and a fallback explanation.\n",
    "      - Otherwise, prompts the LLM to detect misleading or unsupported claims.\n",
    "    \"\"\"\n",
    "    if not evidence:\n",
    "        return json.dumps({\n",
    "            \"is_greenwashing\": False,\n",
    "            \"explanation\": \"No company information available; cannot confirm or deny greenwashing.\"\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a sustainability analyst.\n",
    "User claim: \"{marketing_statement}\"\n",
    "Company info (RAG results): {json.dumps(evidence, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{ \n",
    "  \"is_greenwashing\": <true|false>,\n",
    "  \"explanation\": \"<quote relevant passages and justify your decision>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Detect greenwashing in marketing copy.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "@function_tool\n",
    "def rewrite_statement(original_statement: str, analysis_json: str) -> str:\n",
    "    \"\"\"\n",
    "    Rewrites a marketing statement to remove any greenwashing, based on analysis.\n",
    "\n",
    "    Input:\n",
    "      original_statement (str): The original marketing copy.\n",
    "      analysis_json (str): JSON output from `analyze_greenwashing` tool.\n",
    "    Output:\n",
    "      str: A JSON-formatted string with fields:\n",
    "        {\n",
    "          \"revised_statement\": str,  # Corrected marketing copy\n",
    "          \"justification\": str       # How the rewrite improves honesty\n",
    "        }\n",
    "\n",
    "    Behavior:\n",
    "      - If analysis_json indicates no greenwashing, echoes original with explanation.\n",
    "      - Otherwise, prompts the LLM to produce a rewritten, accurate statement.\n",
    "    \"\"\"\n",
    "    analysis = json.loads(analysis_json)\n",
    "    if not analysis.get(\"is_greenwashing\", False):\n",
    "        return json.dumps({\n",
    "            \"revised_statement\": original_statement,\n",
    "            \"justification\": analysis[\"explanation\"]\n",
    "        })\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a copy editor focused on sustainability accuracy.\n",
    "Original statement: \"{original_statement}\"\n",
    "Greenwashing analysis:\n",
    "{json.dumps(analysis, indent=2)}\n",
    "\n",
    "Respond with valid JSON exactly in this form:\n",
    "{{\n",
    "  \"revised_statement\": \"<rewrite to avoid any misleading claims>\",\n",
    "  \"justification\": \"<explain how the rewrite improves honesty>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    resp = completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Rewrite marketing copy to avoid greenwashing.\"},\n",
    "            {\"role\": \"user\",   \"content\": prompt}\n",
    "        ],\n",
    "        model=MODEL,\n",
    "        api_key=API_KEY\n",
    "    )\n",
    "    return clean_groq_output(resp.choices[0].message.content)\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Agent setup â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "set_tracing_disabled(True)\n",
    "agent = Agent(\n",
    "    name=\"GreenwashingInspector\",\n",
    "    instructions=(\n",
    "      \"You are an AI that detects and corrects greenwashing in marketing statements.\\n\\n\"\n",
    "      \"Use these tools:\\n\"\n",
    "      \"- retrieve_evidence(query) to get only factual company sustainability data.\\n\"\n",
    "      \"- retrieve_laws(query) to get factual laws and regulations related to greenwashing.\\n\"\n",
    "      \"- analyze_greenwashing(statement, evidence) to decide if the claim is greenwashing.\\n\"\n",
    "      \"- rewrite_statement(original, analysis_json) to output a corrected version.\\n\\n\"\n",
    "      \"For every input statement, return exactly:\\n\\n\"\n",
    "      \"1. Retrieved Evidence\\n\"\n",
    "      \"   Concise facts from retrieve_evidence(query).\\n\\n\"\n",
    "      \"2. Conclusion\\n\"\n",
    "      \"   **Greenwashing Detected** or **No Greenwashing Detected**.\\n\\n\"\n",
    "      \"3. Justification\\n\"\n",
    "      \"   Brief reason quoting only the retrieved evidence. Here also refer to the retrieved laws and regulations that are potentially violated\\n\\n\"\n",
    "      \"4. Rewritten Statement\\n\"\n",
    "      \"   Accurate, transparent claim from rewrite_statement.\\n\\n\"\n",
    "      \"5. Suggestions for Improvement\\n\"\n",
    "      \"   2â€“3 concise, evidence-based edits.\\n\\n\"\n",
    "      \"6. Greenwashing Category\\n\"\n",
    "      \"   Choose one and explain with evidence:\\n\"\n",
    "      \"     a) Ambiguous Claims: Vague, metric-free language.\\n\"\n",
    "      \"     b) Hidden Trade-offs: Only one eco aspect highlighted.\\n\"\n",
    "      \"     c) Visual Deception: Misleading imagery.\\n\"\n",
    "      \"     d) Misleading Metrics: Incorrect or unverified numbers.\\n\"\n",
    "      \"     e) Empty Promises: Commitments without a real plan.\\n\"\n",
    "      \"     f) Unverified Certifications: Fake or non-verified labels.\\n\"\n",
    "      \"     g) Compliance as Leadership: Framing legal duty as a choice.\\n\"\n",
    "\n",
    "    ),\n",
    "    model=LitellmModel(model=MODEL, api_key=API_KEY),\n",
    "    tools=[retrieve_evidence, retrieve_laws, analyze_greenwashing, rewrite_statement],\n",
    ")\n",
    "\n",
    "# â€”â€”â€”â€”â€”â€”â€” Example run â€”â€”â€”â€”â€”â€”â€”\n",
    "\n",
    "async def main():\n",
    "    # Test with a sample marketing statement\n",
    "    statement = \"Our operations are 100% carbon neutral\"\n",
    "    result = await Runner.run(agent, statement)\n",
    "    print(parse_agent_output(result.final_output))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    #asyncio.run(main())\n",
    "    await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
